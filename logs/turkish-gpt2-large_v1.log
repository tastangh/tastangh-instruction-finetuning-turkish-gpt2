2024-12-24 21:43:17,794 - INFO - [INFO] Eğitim başlıyor: Model=ytu-ce-cosmos/turkish-gpt2-large, Dataset=v1
2024-12-24 21:43:19,623 - INFO - Dataset başarıyla yüklendi: v1
2024-12-24 21:43:19,624 - INFO - Model ve tokenizer yükleniyor: ytu-ce-cosmos/turkish-gpt2-large
2024-12-24 21:44:39,988 - INFO - Model ve tokenizer başarıyla yüklendi: ytu-ce-cosmos/turkish-gpt2-large
2024-12-24 21:44:39,988 - INFO - Model ytu-ce-cosmos/turkish-gpt2-large ince ayar işlemi başlatılıyor.
2024-12-24 21:44:45,591 - INFO - Dataset başarıyla işlendi: max_seq_length=256
2024-12-24 21:46:59,152 - INFO - Training Logs at step 100: {'loss': 27.7368, 'grad_norm': 7.127327919006348, 'learning_rate': 2.45e-05, 'epoch': 0.023909145248057383}
2024-12-24 21:48:05,335 - INFO - Training Logs at step 150: {'loss': 26.0627, 'grad_norm': 12.641446113586426, 'learning_rate': 4.9500000000000004e-05, 'epoch': 0.04781829049611477}
2024-12-24 21:49:12,431 - INFO - Training Logs at step 200: {'loss': 24.5332, 'grad_norm': 9.790253639221191, 'learning_rate': 4.876946258161728e-05, 'epoch': 0.07172743574417215}
2024-12-24 21:50:19,424 - INFO - Training Logs at step 250: {'loss': 24.6212, 'grad_norm': 8.987465858459473, 'learning_rate': 4.751381215469613e-05, 'epoch': 0.09563658099222953}
2024-12-24 21:51:26,565 - INFO - Training Logs at step 300: {'loss': 25.2716, 'grad_norm': 12.994396209716797, 'learning_rate': 4.625816172777499e-05, 'epoch': 0.1195457262402869}
2024-12-24 21:52:33,835 - INFO - Training Logs at step 350: {'loss': 24.5034, 'grad_norm': 13.56009578704834, 'learning_rate': 4.500251130085384e-05, 'epoch': 0.1434548714883443}
2024-12-24 21:53:40,579 - INFO - Training Logs at step 400: {'loss': 24.4702, 'grad_norm': 16.52023696899414, 'learning_rate': 4.37468608739327e-05, 'epoch': 0.16736401673640167}
2024-12-24 21:54:47,261 - INFO - Training Logs at step 450: {'loss': 23.9783, 'grad_norm': 15.751935958862305, 'learning_rate': 4.249121044701155e-05, 'epoch': 0.19127316198445907}
2024-12-24 21:55:53,593 - INFO - Training Logs at step 500: {'loss': 24.1548, 'grad_norm': 14.41753101348877, 'learning_rate': 4.123556002009041e-05, 'epoch': 0.21518230723251644}
2024-12-24 21:57:00,050 - INFO - Training Logs at step 550: {'loss': 24.3465, 'grad_norm': 13.824969291687012, 'learning_rate': 3.997990959316926e-05, 'epoch': 0.2390914524805738}
2024-12-24 21:58:06,477 - INFO - Training Logs at step 600: {'loss': 23.8732, 'grad_norm': 15.641616821289062, 'learning_rate': 3.872425916624812e-05, 'epoch': 0.2630005977286312}
2024-12-24 21:59:13,408 - INFO - Training Logs at step 650: {'loss': 23.5006, 'grad_norm': 19.32453155517578, 'learning_rate': 3.746860873932697e-05, 'epoch': 0.2869097429766886}
2024-12-24 22:00:20,786 - INFO - Training Logs at step 700: {'loss': 23.8853, 'grad_norm': 11.470455169677734, 'learning_rate': 3.621295831240583e-05, 'epoch': 0.31081888822474596}
2024-12-24 22:01:27,967 - INFO - Training Logs at step 750: {'loss': 23.6943, 'grad_norm': 18.679157257080078, 'learning_rate': 3.495730788548468e-05, 'epoch': 0.33472803347280333}
2024-12-24 22:02:35,206 - INFO - Training Logs at step 800: {'loss': 23.5301, 'grad_norm': 12.818458557128906, 'learning_rate': 3.370165745856354e-05, 'epoch': 0.3586371787208607}
2024-12-24 22:03:42,193 - INFO - Training Logs at step 850: {'loss': 24.0962, 'grad_norm': 16.509119033813477, 'learning_rate': 3.244600703164239e-05, 'epoch': 0.38254632396891813}
2024-12-24 22:04:48,811 - INFO - Training Logs at step 900: {'loss': 23.9214, 'grad_norm': 13.640236854553223, 'learning_rate': 3.119035660472125e-05, 'epoch': 0.4064554692169755}
2024-12-24 22:05:55,551 - INFO - Training Logs at step 950: {'loss': 23.0977, 'grad_norm': 13.102363586425781, 'learning_rate': 2.9934706177800103e-05, 'epoch': 0.4303646144650329}
2024-12-24 22:07:02,296 - INFO - Training Logs at step 1000: {'loss': 22.9736, 'grad_norm': 16.225576400756836, 'learning_rate': 2.8679055750878958e-05, 'epoch': 0.45427375971309025}
2024-12-24 22:08:09,205 - INFO - Training Logs at step 1050: {'loss': 23.4632, 'grad_norm': 14.845603942871094, 'learning_rate': 2.7423405323957813e-05, 'epoch': 0.4781829049611476}
2024-12-24 22:09:15,999 - INFO - Training Logs at step 1100: {'loss': 23.348, 'grad_norm': 9.815279960632324, 'learning_rate': 2.6167754897036668e-05, 'epoch': 0.502092050209205}
2024-12-24 22:10:23,018 - INFO - Training Logs at step 1150: {'loss': 23.698, 'grad_norm': 13.512007713317871, 'learning_rate': 2.4912104470115523e-05, 'epoch': 0.5260011954572624}
2024-12-24 22:11:30,208 - INFO - Training Logs at step 1200: {'loss': 23.7054, 'grad_norm': 12.033914566040039, 'learning_rate': 2.3656454043194374e-05, 'epoch': 0.5499103407053197}
2024-12-24 22:12:37,452 - INFO - Training Logs at step 1250: {'loss': 23.5951, 'grad_norm': 13.159575462341309, 'learning_rate': 2.240080361627323e-05, 'epoch': 0.5738194859533772}
2024-12-24 22:13:44,424 - INFO - Training Logs at step 1300: {'loss': 23.6843, 'grad_norm': 16.5561580657959, 'learning_rate': 2.1145153189352084e-05, 'epoch': 0.5977286312014346}
2024-12-24 22:14:51,534 - INFO - Training Logs at step 1350: {'loss': 22.9379, 'grad_norm': 12.23227310180664, 'learning_rate': 1.988950276243094e-05, 'epoch': 0.6216377764494919}
2024-12-24 22:15:59,232 - INFO - Training Logs at step 1400: {'loss': 23.1429, 'grad_norm': 15.39854907989502, 'learning_rate': 1.8633852335509794e-05, 'epoch': 0.6455469216975493}
2024-12-24 22:17:06,729 - INFO - Training Logs at step 1450: {'loss': 23.5425, 'grad_norm': 14.216815948486328, 'learning_rate': 1.737820190858865e-05, 'epoch': 0.6694560669456067}
2024-12-24 22:18:13,730 - INFO - Training Logs at step 1500: {'loss': 23.7219, 'grad_norm': 12.982029914855957, 'learning_rate': 1.6122551481667504e-05, 'epoch': 0.6933652121936641}
2024-12-24 22:19:20,492 - INFO - Training Logs at step 1550: {'loss': 23.6918, 'grad_norm': 14.19096565246582, 'learning_rate': 1.486690105474636e-05, 'epoch': 0.7172743574417214}
2024-12-24 22:20:27,187 - INFO - Training Logs at step 1600: {'loss': 23.2018, 'grad_norm': 13.933319091796875, 'learning_rate': 1.3611250627825214e-05, 'epoch': 0.7411835026897788}
2024-12-24 22:21:33,983 - INFO - Training Logs at step 1650: {'loss': 23.0013, 'grad_norm': 11.856423377990723, 'learning_rate': 1.235560020090407e-05, 'epoch': 0.7650926479378363}
2024-12-24 22:22:41,190 - INFO - Training Logs at step 1700: {'loss': 23.5798, 'grad_norm': 15.30795955657959, 'learning_rate': 1.1099949773982923e-05, 'epoch': 0.7890017931858936}
2024-12-24 22:23:48,202 - INFO - Training Logs at step 1750: {'loss': 23.5574, 'grad_norm': 12.517081260681152, 'learning_rate': 9.844299347061778e-06, 'epoch': 0.812910938433951}
2024-12-24 22:24:55,523 - INFO - Training Logs at step 1800: {'loss': 23.7517, 'grad_norm': 10.292468070983887, 'learning_rate': 8.613761928679057e-06, 'epoch': 0.8368200836820083}
2024-12-24 22:26:02,470 - INFO - Training Logs at step 1850: {'loss': 23.0024, 'grad_norm': 12.018068313598633, 'learning_rate': 7.358111501757911e-06, 'epoch': 0.8607292289300658}
2024-12-24 22:27:09,526 - INFO - Training Logs at step 1900: {'loss': 23.6507, 'grad_norm': 18.36246681213379, 'learning_rate': 6.102461074836766e-06, 'epoch': 0.8846383741781231}
2024-12-24 22:28:17,022 - INFO - Training Logs at step 1950: {'loss': 23.0396, 'grad_norm': 12.787823677062988, 'learning_rate': 4.846810647915621e-06, 'epoch': 0.9085475194261805}
2024-12-24 22:29:24,874 - INFO - Training Logs at step 2000: {'loss': 23.6324, 'grad_norm': 13.841842651367188, 'learning_rate': 3.5911602209944753e-06, 'epoch': 0.9324566646742379}
2024-12-24 22:30:31,936 - INFO - Training Logs at step 2050: {'loss': 23.1408, 'grad_norm': 19.318008422851562, 'learning_rate': 2.33550979407333e-06, 'epoch': 0.9563658099222953}
2024-12-24 22:31:28,836 - INFO - Model ytu-ce-cosmos/turkish-gpt2-large ince ayar işlemi başarıyla tamamlandı.
2024-12-24 22:31:28,836 - INFO - Model ve tokenizer kaydediliyor: ./models/turkish-gpt2-large_v1
2024-12-24 22:31:37,568 - INFO - Model ./models/turkish-gpt2-large_v1 dizinine başarıyla kaydedildi.
2024-12-24 22:31:37,568 - INFO - [SUCCESS] Eğitim tamamlandı: Model=ytu-ce-cosmos/turkish-gpt2-large, Dataset=v1
