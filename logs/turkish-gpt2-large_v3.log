2024-12-24 18:18:45,189 - INFO - [INFO] Eğitim başlıyor: Model=ytu-ce-cosmos/turkish-gpt2-large, Dataset=v3
2024-12-24 18:18:50,327 - INFO - Dataset başarıyla yüklendi: v3
2024-12-24 18:18:50,328 - INFO - Model ve tokenizer yükleniyor: ytu-ce-cosmos/turkish-gpt2-large
2024-12-24 18:18:52,587 - INFO - Model ve tokenizer başarıyla yüklendi: ytu-ce-cosmos/turkish-gpt2-large
2024-12-24 18:18:52,587 - INFO - Model ytu-ce-cosmos/turkish-gpt2-large ince ayar işlemi başlatılıyor.
2024-12-24 18:19:16,638 - INFO - Dataset başarıyla işlendi: max_seq_length=256
2024-12-24 18:21:31,528 - INFO - Training Logs at step 100: {'loss': 28.2008, 'grad_norm': 7.387266159057617, 'learning_rate': 2.45e-05, 'epoch': 0.005857115663391563}
2024-12-24 18:22:38,768 - INFO - Training Logs at step 150: {'loss': 25.9361, 'grad_norm': 17.77528953552246, 'learning_rate': 4.9500000000000004e-05, 'epoch': 0.011714231326783125}
2024-12-24 18:23:45,989 - INFO - Training Logs at step 200: {'loss': 24.7228, 'grad_norm': 16.527563095092773, 'learning_rate': 4.9709577999051685e-05, 'epoch': 0.017571346990174687}
2024-12-24 18:24:53,111 - INFO - Training Logs at step 250: {'loss': 24.5132, 'grad_norm': 11.681530952453613, 'learning_rate': 4.941322901849218e-05, 'epoch': 0.02342846265356625}
2024-12-24 18:26:00,146 - INFO - Training Logs at step 300: {'loss': 23.6585, 'grad_norm': 12.420706748962402, 'learning_rate': 4.911688003793267e-05, 'epoch': 0.029285578316957814}
2024-12-24 18:27:07,292 - INFO - Training Logs at step 350: {'loss': 24.2494, 'grad_norm': 12.537506103515625, 'learning_rate': 4.882053105737316e-05, 'epoch': 0.035142693980349374}
2024-12-24 18:28:14,302 - INFO - Training Logs at step 400: {'loss': 23.5971, 'grad_norm': 11.649422645568848, 'learning_rate': 4.852418207681366e-05, 'epoch': 0.04099980964374094}
2024-12-24 18:29:21,736 - INFO - Training Logs at step 450: {'loss': 23.656, 'grad_norm': 11.771559715270996, 'learning_rate': 4.822783309625415e-05, 'epoch': 0.0468569253071325}
2024-12-24 18:30:28,727 - INFO - Training Logs at step 500: {'loss': 23.6192, 'grad_norm': 12.669580459594727, 'learning_rate': 4.793148411569465e-05, 'epoch': 0.05271404097052407}
2024-12-24 18:31:35,847 - INFO - Training Logs at step 550: {'loss': 23.479, 'grad_norm': 11.830558776855469, 'learning_rate': 4.763513513513514e-05, 'epoch': 0.05857115663391563}
2024-12-24 18:32:43,615 - INFO - Training Logs at step 600: {'loss': 23.3163, 'grad_norm': 9.246711730957031, 'learning_rate': 4.733878615457563e-05, 'epoch': 0.06442827229730719}
2024-12-24 18:33:50,979 - INFO - Training Logs at step 650: {'loss': 22.9733, 'grad_norm': 11.28056526184082, 'learning_rate': 4.7042437174016126e-05, 'epoch': 0.07028538796069875}
2024-12-24 18:34:58,110 - INFO - Training Logs at step 700: {'loss': 23.2677, 'grad_norm': 10.061939239501953, 'learning_rate': 4.6746088193456616e-05, 'epoch': 0.07614250362409032}
2024-12-24 18:36:05,140 - INFO - Training Logs at step 750: {'loss': 23.2063, 'grad_norm': 11.10335636138916, 'learning_rate': 4.644973921289711e-05, 'epoch': 0.08199961928748188}
2024-12-24 18:37:12,186 - INFO - Training Logs at step 800: {'loss': 23.0865, 'grad_norm': 14.275832176208496, 'learning_rate': 4.6153390232337604e-05, 'epoch': 0.08785673495087344}
2024-12-24 18:38:19,456 - INFO - Training Logs at step 850: {'loss': 23.0907, 'grad_norm': 10.642051696777344, 'learning_rate': 4.5857041251778094e-05, 'epoch': 0.093713850614265}
2024-12-24 18:39:26,413 - INFO - Training Logs at step 900: {'loss': 23.2136, 'grad_norm': 10.848442077636719, 'learning_rate': 4.556069227121859e-05, 'epoch': 0.09957096627765656}
2024-12-24 18:40:33,198 - INFO - Training Logs at step 950: {'loss': 22.9614, 'grad_norm': 9.807119369506836, 'learning_rate': 4.526434329065908e-05, 'epoch': 0.10542808194104814}
2024-12-24 18:41:40,262 - INFO - Training Logs at step 1000: {'loss': 23.275, 'grad_norm': 10.570998191833496, 'learning_rate': 4.496799431009958e-05, 'epoch': 0.1112851976044397}
2024-12-24 18:42:47,351 - INFO - Training Logs at step 1050: {'loss': 22.9726, 'grad_norm': 11.447432518005371, 'learning_rate': 4.467164532954007e-05, 'epoch': 0.11714231326783126}
2024-12-24 18:43:54,377 - INFO - Training Logs at step 1100: {'loss': 23.2404, 'grad_norm': 8.188444137573242, 'learning_rate': 4.437529634898056e-05, 'epoch': 0.12299942893122282}
2024-12-24 18:45:01,284 - INFO - Training Logs at step 1150: {'loss': 22.7534, 'grad_norm': 10.726530075073242, 'learning_rate': 4.407894736842105e-05, 'epoch': 0.12885654459461438}
2024-12-24 18:46:08,321 - INFO - Training Logs at step 1200: {'loss': 22.5662, 'grad_norm': 10.887279510498047, 'learning_rate': 4.378259838786155e-05, 'epoch': 0.13471366025800594}
2024-12-24 18:47:15,212 - INFO - Training Logs at step 1250: {'loss': 22.9451, 'grad_norm': 19.05506706237793, 'learning_rate': 4.3486249407302045e-05, 'epoch': 0.1405707759213975}
2024-12-24 18:48:22,296 - INFO - Training Logs at step 1300: {'loss': 23.1709, 'grad_norm': 11.808622360229492, 'learning_rate': 4.3189900426742535e-05, 'epoch': 0.14642789158478908}
2024-12-24 18:49:29,244 - INFO - Training Logs at step 1350: {'loss': 22.9814, 'grad_norm': 12.597735404968262, 'learning_rate': 4.2893551446183026e-05, 'epoch': 0.15228500724818064}
2024-12-24 18:50:36,255 - INFO - Training Logs at step 1400: {'loss': 22.8374, 'grad_norm': 12.732637405395508, 'learning_rate': 4.259720246562352e-05, 'epoch': 0.1581421229115722}
2024-12-24 18:51:43,389 - INFO - Training Logs at step 1450: {'loss': 22.6671, 'grad_norm': 12.185186386108398, 'learning_rate': 4.2300853485064014e-05, 'epoch': 0.16399923857496376}
2024-12-24 18:52:50,968 - INFO - Training Logs at step 1500: {'loss': 23.0437, 'grad_norm': 10.795064926147461, 'learning_rate': 4.2004504504504504e-05, 'epoch': 0.16985635423835532}
2024-12-24 18:53:58,572 - INFO - Training Logs at step 1550: {'loss': 23.233, 'grad_norm': 13.18807315826416, 'learning_rate': 4.1708155523944994e-05, 'epoch': 0.17571346990174688}
2024-12-24 18:55:05,539 - INFO - Training Logs at step 1600: {'loss': 22.9805, 'grad_norm': 12.222118377685547, 'learning_rate': 4.14118065433855e-05, 'epoch': 0.18157058556513844}
2024-12-24 18:56:12,440 - INFO - Training Logs at step 1650: {'loss': 22.776, 'grad_norm': 13.7548828125, 'learning_rate': 4.111545756282599e-05, 'epoch': 0.18742770122853}
2024-12-24 18:57:19,765 - INFO - Training Logs at step 1700: {'loss': 22.7512, 'grad_norm': 9.109784126281738, 'learning_rate': 4.081910858226648e-05, 'epoch': 0.19328481689192156}
2024-12-24 18:58:27,149 - INFO - Training Logs at step 1750: {'loss': 22.6271, 'grad_norm': 9.384952545166016, 'learning_rate': 4.052275960170697e-05, 'epoch': 0.19914193255531312}
2024-12-24 18:59:34,150 - INFO - Training Logs at step 1800: {'loss': 23.2711, 'grad_norm': 15.267752647399902, 'learning_rate': 4.022641062114747e-05, 'epoch': 0.2049990482187047}
2024-12-24 19:00:41,243 - INFO - Training Logs at step 1850: {'loss': 22.9287, 'grad_norm': 14.969338417053223, 'learning_rate': 3.993006164058796e-05, 'epoch': 0.21085616388209627}
2024-12-24 19:01:48,289 - INFO - Training Logs at step 1900: {'loss': 22.7828, 'grad_norm': 13.346029281616211, 'learning_rate': 3.963371266002845e-05, 'epoch': 0.21671327954548783}
2024-12-24 19:02:55,381 - INFO - Training Logs at step 1950: {'loss': 22.636, 'grad_norm': 10.50365924835205, 'learning_rate': 3.9337363679468945e-05, 'epoch': 0.2225703952088794}
2024-12-24 19:04:02,432 - INFO - Training Logs at step 2000: {'loss': 22.5892, 'grad_norm': 12.075852394104004, 'learning_rate': 3.904101469890944e-05, 'epoch': 0.22842751087227095}
2024-12-24 19:05:09,543 - INFO - Training Logs at step 2050: {'loss': 22.9683, 'grad_norm': 12.955620765686035, 'learning_rate': 3.874466571834993e-05, 'epoch': 0.2342846265356625}
2024-12-24 19:06:16,500 - INFO - Training Logs at step 2100: {'loss': 23.0117, 'grad_norm': 15.245003700256348, 'learning_rate': 3.844831673779042e-05, 'epoch': 0.24014174219905407}
2024-12-24 19:07:23,325 - INFO - Training Logs at step 2150: {'loss': 22.3851, 'grad_norm': 13.630210876464844, 'learning_rate': 3.8151967757230914e-05, 'epoch': 0.24599885786244563}
2024-12-24 19:08:30,284 - INFO - Training Logs at step 2200: {'loss': 23.0488, 'grad_norm': 10.813436508178711, 'learning_rate': 3.785561877667141e-05, 'epoch': 0.2518559735258372}
2024-12-24 19:09:37,231 - INFO - Training Logs at step 2250: {'loss': 22.8024, 'grad_norm': 9.590424537658691, 'learning_rate': 3.75592697961119e-05, 'epoch': 0.25771308918922875}
2024-12-24 19:10:44,022 - INFO - Training Logs at step 2300: {'loss': 22.9285, 'grad_norm': 18.458887100219727, 'learning_rate': 3.72629208155524e-05, 'epoch': 0.26357020485262034}
2024-12-24 19:11:50,731 - INFO - Training Logs at step 2350: {'loss': 22.4452, 'grad_norm': 12.960753440856934, 'learning_rate': 3.696657183499289e-05, 'epoch': 0.26942732051601187}
2024-12-24 19:12:57,466 - INFO - Training Logs at step 2400: {'loss': 22.2611, 'grad_norm': 10.155253410339355, 'learning_rate': 3.6670222854433386e-05, 'epoch': 0.27528443617940346}
2024-12-24 19:14:04,151 - INFO - Training Logs at step 2450: {'loss': 22.3141, 'grad_norm': 11.792529106140137, 'learning_rate': 3.637387387387388e-05, 'epoch': 0.281141551842795}
2024-12-24 19:15:11,036 - INFO - Training Logs at step 2500: {'loss': 22.7609, 'grad_norm': 15.85474681854248, 'learning_rate': 3.607752489331437e-05, 'epoch': 0.2869986675061866}
2024-12-24 19:16:17,688 - INFO - Training Logs at step 2550: {'loss': 22.5232, 'grad_norm': 11.262548446655273, 'learning_rate': 3.578117591275486e-05, 'epoch': 0.29285578316957817}
2024-12-24 19:17:24,404 - INFO - Training Logs at step 2600: {'loss': 22.838, 'grad_norm': 14.611357688903809, 'learning_rate': 3.5490753911806547e-05, 'epoch': 0.2987128988329697}
2024-12-24 19:18:31,163 - INFO - Training Logs at step 2650: {'loss': 22.567, 'grad_norm': 14.40324878692627, 'learning_rate': 3.519440493124704e-05, 'epoch': 0.3045700144963613}
2024-12-24 19:19:37,885 - INFO - Training Logs at step 2700: {'loss': 22.7446, 'grad_norm': 14.409476280212402, 'learning_rate': 3.489805595068753e-05, 'epoch': 0.3104271301597528}
2024-12-24 19:20:44,439 - INFO - Training Logs at step 2750: {'loss': 23.0634, 'grad_norm': 12.185219764709473, 'learning_rate': 3.4601706970128025e-05, 'epoch': 0.3162842458231444}
2024-12-24 19:21:51,150 - INFO - Training Logs at step 2800: {'loss': 22.6693, 'grad_norm': 14.801321029663086, 'learning_rate': 3.4305357989568515e-05, 'epoch': 0.32214136148653594}
2024-12-24 19:22:57,824 - INFO - Training Logs at step 2850: {'loss': 22.1208, 'grad_norm': 7.845783233642578, 'learning_rate': 3.400900900900901e-05, 'epoch': 0.3279984771499275}
2024-12-24 19:24:04,549 - INFO - Training Logs at step 2900: {'loss': 22.4422, 'grad_norm': 12.799345970153809, 'learning_rate': 3.37126600284495e-05, 'epoch': 0.33385559281331906}
2024-12-24 19:25:11,128 - INFO - Training Logs at step 2950: {'loss': 22.1056, 'grad_norm': 13.117740631103516, 'learning_rate': 3.341631104789e-05, 'epoch': 0.33971270847671065}
2024-12-24 19:26:17,719 - INFO - Training Logs at step 3000: {'loss': 22.2283, 'grad_norm': 13.278261184692383, 'learning_rate': 3.311996206733049e-05, 'epoch': 0.34556982414010223}
2024-12-24 19:27:24,270 - INFO - Training Logs at step 3050: {'loss': 22.1044, 'grad_norm': 9.810136795043945, 'learning_rate': 3.282361308677098e-05, 'epoch': 0.35142693980349377}
2024-12-24 19:28:30,951 - INFO - Training Logs at step 3100: {'loss': 23.2229, 'grad_norm': 12.843010902404785, 'learning_rate': 3.252726410621147e-05, 'epoch': 0.35728405546688535}
2024-12-24 19:29:37,536 - INFO - Training Logs at step 3150: {'loss': 22.4007, 'grad_norm': 15.546578407287598, 'learning_rate': 3.223091512565197e-05, 'epoch': 0.3631411711302769}
2024-12-24 19:30:44,240 - INFO - Training Logs at step 3200: {'loss': 22.3588, 'grad_norm': 12.812735557556152, 'learning_rate': 3.1934566145092466e-05, 'epoch': 0.3689982867936685}
2024-12-24 19:31:51,026 - INFO - Training Logs at step 3250: {'loss': 22.346, 'grad_norm': 14.473440170288086, 'learning_rate': 3.1638217164532956e-05, 'epoch': 0.37485540245706}
2024-12-24 19:32:57,748 - INFO - Training Logs at step 3300: {'loss': 22.2041, 'grad_norm': 13.277328491210938, 'learning_rate': 3.134186818397345e-05, 'epoch': 0.3807125181204516}
2024-12-24 19:34:04,471 - INFO - Training Logs at step 3350: {'loss': 22.3566, 'grad_norm': 13.904232025146484, 'learning_rate': 3.1045519203413944e-05, 'epoch': 0.3865696337838431}
2024-12-24 19:35:11,230 - INFO - Training Logs at step 3400: {'loss': 22.1957, 'grad_norm': 14.440776824951172, 'learning_rate': 3.0749170222854434e-05, 'epoch': 0.3924267494472347}
2024-12-24 19:36:17,905 - INFO - Training Logs at step 3450: {'loss': 22.7061, 'grad_norm': 13.79338550567627, 'learning_rate': 3.0452821242294928e-05, 'epoch': 0.39828386511062625}
2024-12-24 19:37:24,570 - INFO - Training Logs at step 3500: {'loss': 22.281, 'grad_norm': 12.4085054397583, 'learning_rate': 3.015647226173542e-05, 'epoch': 0.40414098077401783}
2024-12-24 19:38:31,101 - INFO - Training Logs at step 3550: {'loss': 22.3741, 'grad_norm': 14.102060317993164, 'learning_rate': 2.9860123281175916e-05, 'epoch': 0.4099980964374094}
2024-12-24 19:39:37,943 - INFO - Training Logs at step 3600: {'loss': 22.0878, 'grad_norm': 14.564072608947754, 'learning_rate': 2.956377430061641e-05, 'epoch': 0.41585521210080095}
2024-12-24 19:40:44,689 - INFO - Training Logs at step 3650: {'loss': 22.4175, 'grad_norm': 15.475808143615723, 'learning_rate': 2.92674253200569e-05, 'epoch': 0.42171232776419254}
2024-12-24 19:41:51,154 - INFO - Training Logs at step 3700: {'loss': 22.459, 'grad_norm': 11.64255142211914, 'learning_rate': 2.8971076339497394e-05, 'epoch': 0.4275694434275841}
2024-12-24 19:42:57,659 - INFO - Training Logs at step 3750: {'loss': 22.1283, 'grad_norm': 10.89892864227295, 'learning_rate': 2.8674727358937888e-05, 'epoch': 0.43342655909097566}
2024-12-24 19:44:04,187 - INFO - Training Logs at step 3800: {'loss': 22.5557, 'grad_norm': 14.659709930419922, 'learning_rate': 2.8378378378378378e-05, 'epoch': 0.4392836747543672}
2024-12-24 19:45:10,824 - INFO - Training Logs at step 3850: {'loss': 21.8579, 'grad_norm': 12.717020034790039, 'learning_rate': 2.8082029397818872e-05, 'epoch': 0.4451407904177588}
2024-12-24 19:46:17,648 - INFO - Training Logs at step 3900: {'loss': 22.4766, 'grad_norm': 12.18062973022461, 'learning_rate': 2.7785680417259363e-05, 'epoch': 0.4509979060811503}
2024-12-24 19:47:24,144 - INFO - Training Logs at step 3950: {'loss': 22.4185, 'grad_norm': 13.183505058288574, 'learning_rate': 2.748933143669986e-05, 'epoch': 0.4568550217445419}
2024-12-24 19:48:30,740 - INFO - Training Logs at step 4000: {'loss': 22.6599, 'grad_norm': 13.159879684448242, 'learning_rate': 2.7192982456140354e-05, 'epoch': 0.4627121374079335}
2024-12-24 19:49:37,288 - INFO - Training Logs at step 4050: {'loss': 22.5864, 'grad_norm': 13.086212158203125, 'learning_rate': 2.6896633475580847e-05, 'epoch': 0.468569253071325}
2024-12-24 19:50:43,822 - INFO - Training Logs at step 4100: {'loss': 22.1507, 'grad_norm': 13.066152572631836, 'learning_rate': 2.6600284495021338e-05, 'epoch': 0.4744263687347166}
2024-12-24 19:51:50,274 - INFO - Training Logs at step 4150: {'loss': 22.1287, 'grad_norm': 11.295557022094727, 'learning_rate': 2.6303935514461832e-05, 'epoch': 0.48028348439810814}
2024-12-24 19:52:56,643 - INFO - Training Logs at step 4200: {'loss': 22.2029, 'grad_norm': 15.256978034973145, 'learning_rate': 2.6007586533902322e-05, 'epoch': 0.48614060006149973}
2024-12-24 19:54:03,220 - INFO - Training Logs at step 4250: {'loss': 22.1843, 'grad_norm': 9.67504596710205, 'learning_rate': 2.5711237553342816e-05, 'epoch': 0.49199771572489126}
2024-12-24 19:55:09,887 - INFO - Training Logs at step 4300: {'loss': 21.5734, 'grad_norm': 14.498262405395508, 'learning_rate': 2.5414888572783313e-05, 'epoch': 0.49785483138828285}
2024-12-24 19:56:16,630 - INFO - Training Logs at step 4350: {'loss': 21.8559, 'grad_norm': 13.684861183166504, 'learning_rate': 2.5118539592223807e-05, 'epoch': 0.5037119470516744}
2024-12-24 19:57:23,251 - INFO - Training Logs at step 4400: {'loss': 22.1407, 'grad_norm': 17.534496307373047, 'learning_rate': 2.4822190611664297e-05, 'epoch': 0.509569062715066}
2024-12-24 19:58:29,874 - INFO - Training Logs at step 4450: {'loss': 22.5438, 'grad_norm': 11.806013107299805, 'learning_rate': 2.452584163110479e-05, 'epoch': 0.5154261783784575}
2024-12-24 19:59:36,487 - INFO - Training Logs at step 4500: {'loss': 21.7363, 'grad_norm': 13.021819114685059, 'learning_rate': 2.4229492650545282e-05, 'epoch': 0.5212832940418491}
2024-12-24 20:00:43,196 - INFO - Training Logs at step 4550: {'loss': 22.2223, 'grad_norm': 11.022677421569824, 'learning_rate': 2.393314366998578e-05, 'epoch': 0.5271404097052407}
2024-12-24 20:01:49,925 - INFO - Training Logs at step 4600: {'loss': 21.8357, 'grad_norm': 14.625849723815918, 'learning_rate': 2.363679468942627e-05, 'epoch': 0.5329975253686322}
2024-12-24 20:02:56,562 - INFO - Training Logs at step 4650: {'loss': 22.399, 'grad_norm': 16.0195255279541, 'learning_rate': 2.3340445708866763e-05, 'epoch': 0.5388546410320237}
2024-12-24 20:04:03,267 - INFO - Training Logs at step 4700: {'loss': 22.0329, 'grad_norm': 16.3219051361084, 'learning_rate': 2.3044096728307254e-05, 'epoch': 0.5447117566954154}
2024-12-24 20:05:10,078 - INFO - Training Logs at step 4750: {'loss': 22.2247, 'grad_norm': 9.151823997497559, 'learning_rate': 2.274774774774775e-05, 'epoch': 0.5505688723588069}
2024-12-24 20:06:16,925 - INFO - Training Logs at step 4800: {'loss': 22.4139, 'grad_norm': 14.313392639160156, 'learning_rate': 2.245139876718824e-05, 'epoch': 0.5564259880221984}
2024-12-24 20:07:23,566 - INFO - Training Logs at step 4850: {'loss': 22.2898, 'grad_norm': 12.119647026062012, 'learning_rate': 2.2160976766239924e-05, 'epoch': 0.56228310368559}
2024-12-24 20:08:30,074 - INFO - Training Logs at step 4900: {'loss': 22.0321, 'grad_norm': 21.143056869506836, 'learning_rate': 2.186462778568042e-05, 'epoch': 0.5681402193489816}
2024-12-24 20:09:38,039 - INFO - Training Logs at step 4950: {'loss': 22.0971, 'grad_norm': 12.971487045288086, 'learning_rate': 2.156827880512091e-05, 'epoch': 0.5739973350123732}
2024-12-24 20:10:46,644 - INFO - Training Logs at step 5000: {'loss': 21.8033, 'grad_norm': 10.082012176513672, 'learning_rate': 2.1271929824561405e-05, 'epoch': 0.5798544506757647}
2024-12-24 20:12:04,740 - INFO - Training Logs at step 5050: {'loss': 21.855, 'grad_norm': 13.018465042114258, 'learning_rate': 2.0975580844001896e-05, 'epoch': 0.5857115663391563}
2024-12-24 20:13:23,044 - INFO - Training Logs at step 5100: {'loss': 22.0929, 'grad_norm': 11.730849266052246, 'learning_rate': 2.0679231863442393e-05, 'epoch': 0.5915686820025479}
2024-12-24 20:14:30,286 - INFO - Training Logs at step 5150: {'loss': 21.8809, 'grad_norm': 11.583670616149902, 'learning_rate': 2.0382882882882883e-05, 'epoch': 0.5974257976659394}
2024-12-24 20:15:37,324 - INFO - Training Logs at step 5200: {'loss': 21.9772, 'grad_norm': 18.555356979370117, 'learning_rate': 2.0086533902323377e-05, 'epoch': 0.6032829133293309}
2024-12-24 20:16:44,120 - INFO - Training Logs at step 5250: {'loss': 21.8611, 'grad_norm': 10.77509880065918, 'learning_rate': 1.979018492176387e-05, 'epoch': 0.6091400289927226}
2024-12-24 20:17:51,355 - INFO - Training Logs at step 5300: {'loss': 22.4413, 'grad_norm': 13.682451248168945, 'learning_rate': 1.9493835941204365e-05, 'epoch': 0.6149971446561141}
2024-12-24 20:18:58,471 - INFO - Training Logs at step 5350: {'loss': 22.0189, 'grad_norm': 13.553207397460938, 'learning_rate': 1.9197486960644855e-05, 'epoch': 0.6208542603195056}
2024-12-24 20:20:05,353 - INFO - Training Logs at step 5400: {'loss': 21.7227, 'grad_norm': 11.310955047607422, 'learning_rate': 1.890113798008535e-05, 'epoch': 0.6267113759828972}
2024-12-24 20:21:12,745 - INFO - Training Logs at step 5450: {'loss': 22.3169, 'grad_norm': 12.093622207641602, 'learning_rate': 1.8604788999525843e-05, 'epoch': 0.6325684916462888}
2024-12-24 20:22:19,691 - INFO - Training Logs at step 5500: {'loss': 21.9695, 'grad_norm': 15.022014617919922, 'learning_rate': 1.8308440018966337e-05, 'epoch': 0.6384256073096803}
2024-12-24 20:23:26,406 - INFO - Training Logs at step 5550: {'loss': 22.0358, 'grad_norm': 17.80703353881836, 'learning_rate': 1.8012091038406827e-05, 'epoch': 0.6442827229730719}
2024-12-24 20:24:33,060 - INFO - Training Logs at step 5600: {'loss': 22.3422, 'grad_norm': 17.693063735961914, 'learning_rate': 1.7715742057847324e-05, 'epoch': 0.6501398386364635}
2024-12-24 20:25:39,640 - INFO - Training Logs at step 5650: {'loss': 22.1155, 'grad_norm': 17.296180725097656, 'learning_rate': 1.7419393077287815e-05, 'epoch': 0.655996954299855}
2024-12-24 20:26:46,525 - INFO - Training Logs at step 5700: {'loss': 22.5096, 'grad_norm': 11.211774826049805, 'learning_rate': 1.712304409672831e-05, 'epoch': 0.6618540699632466}
2024-12-24 20:27:53,278 - INFO - Training Logs at step 5750: {'loss': 22.0216, 'grad_norm': 13.667004585266113, 'learning_rate': 1.68266951161688e-05, 'epoch': 0.6677111856266381}
2024-12-24 20:28:59,952 - INFO - Training Logs at step 5800: {'loss': 21.6109, 'grad_norm': 15.073934555053711, 'learning_rate': 1.6530346135609296e-05, 'epoch': 0.6735683012900298}
2024-12-24 20:30:06,571 - INFO - Training Logs at step 5850: {'loss': 22.2919, 'grad_norm': 11.600441932678223, 'learning_rate': 1.6233997155049787e-05, 'epoch': 0.6794254169534213}
2024-12-24 20:31:13,415 - INFO - Training Logs at step 5900: {'loss': 22.2784, 'grad_norm': 13.0928316116333, 'learning_rate': 1.593764817449028e-05, 'epoch': 0.6852825326168128}
2024-12-24 20:32:20,009 - INFO - Training Logs at step 5950: {'loss': 21.8688, 'grad_norm': 15.426342964172363, 'learning_rate': 1.564129919393077e-05, 'epoch': 0.6911396482802045}
2024-12-24 20:33:26,648 - INFO - Training Logs at step 6000: {'loss': 22.4271, 'grad_norm': 16.559738159179688, 'learning_rate': 1.5344950213371268e-05, 'epoch': 0.696996763943596}
2024-12-24 20:34:33,463 - INFO - Training Logs at step 6050: {'loss': 22.04, 'grad_norm': 12.643363952636719, 'learning_rate': 1.504860123281176e-05, 'epoch': 0.7028538796069875}
2024-12-24 20:35:40,164 - INFO - Training Logs at step 6100: {'loss': 21.8273, 'grad_norm': 13.384918212890625, 'learning_rate': 1.4752252252252253e-05, 'epoch': 0.7087109952703791}
2024-12-24 20:36:46,731 - INFO - Training Logs at step 6150: {'loss': 22.2994, 'grad_norm': 11.242298126220703, 'learning_rate': 1.4455903271692748e-05, 'epoch': 0.7145681109337707}
2024-12-24 20:37:53,325 - INFO - Training Logs at step 6200: {'loss': 22.0975, 'grad_norm': 13.4358491897583, 'learning_rate': 1.415955429113324e-05, 'epoch': 0.7204252265971622}
2024-12-24 20:38:59,852 - INFO - Training Logs at step 6250: {'loss': 22.2323, 'grad_norm': 14.417387008666992, 'learning_rate': 1.3863205310573732e-05, 'epoch': 0.7262823422605538}
2024-12-24 20:40:06,499 - INFO - Training Logs at step 6300: {'loss': 22.456, 'grad_norm': 16.83258056640625, 'learning_rate': 1.3566856330014224e-05, 'epoch': 0.7321394579239453}
2024-12-24 20:41:14,151 - INFO - Training Logs at step 6350: {'loss': 22.0934, 'grad_norm': 13.058820724487305, 'learning_rate': 1.327050734945472e-05, 'epoch': 0.737996573587337}
2024-12-24 20:42:20,769 - INFO - Training Logs at step 6400: {'loss': 22.1844, 'grad_norm': 13.35044002532959, 'learning_rate': 1.2974158368895212e-05, 'epoch': 0.7438536892507285}
2024-12-24 20:43:27,532 - INFO - Training Logs at step 6450: {'loss': 21.788, 'grad_norm': 11.147031784057617, 'learning_rate': 1.2677809388335704e-05, 'epoch': 0.74971080491412}
2024-12-24 20:44:34,123 - INFO - Training Logs at step 6500: {'loss': 22.2094, 'grad_norm': 13.21153736114502, 'learning_rate': 1.2381460407776198e-05, 'epoch': 0.7555679205775117}
2024-12-24 20:45:40,811 - INFO - Training Logs at step 6550: {'loss': 22.0172, 'grad_norm': 15.848851203918457, 'learning_rate': 1.2085111427216692e-05, 'epoch': 0.7614250362409032}
2024-12-24 20:46:47,523 - INFO - Training Logs at step 6600: {'loss': 22.1111, 'grad_norm': 15.1506986618042, 'learning_rate': 1.1788762446657184e-05, 'epoch': 0.7672821519042947}
2024-12-24 20:47:54,242 - INFO - Training Logs at step 6650: {'loss': 22.1557, 'grad_norm': 10.220020294189453, 'learning_rate': 1.1492413466097678e-05, 'epoch': 0.7731392675676863}
2024-12-24 20:49:00,837 - INFO - Training Logs at step 6700: {'loss': 22.3694, 'grad_norm': 11.395912170410156, 'learning_rate': 1.119606448553817e-05, 'epoch': 0.7789963832310779}
2024-12-24 20:50:07,409 - INFO - Training Logs at step 6750: {'loss': 21.6793, 'grad_norm': 9.068028450012207, 'learning_rate': 1.0899715504978664e-05, 'epoch': 0.7848534988944694}
2024-12-24 20:51:13,955 - INFO - Training Logs at step 6800: {'loss': 22.4048, 'grad_norm': 15.188146591186523, 'learning_rate': 1.0603366524419156e-05, 'epoch': 0.790710614557861}
2024-12-24 20:52:20,707 - INFO - Training Logs at step 6850: {'loss': 22.1848, 'grad_norm': 12.807571411132812, 'learning_rate': 1.030701754385965e-05, 'epoch': 0.7965677302212525}
2024-12-24 20:53:27,195 - INFO - Training Logs at step 6900: {'loss': 22.201, 'grad_norm': 15.944014549255371, 'learning_rate': 1.0010668563300142e-05, 'epoch': 0.8024248458846441}
2024-12-24 20:54:33,324 - INFO - Training Logs at step 6950: {'loss': 22.3121, 'grad_norm': 11.143658638000488, 'learning_rate': 9.714319582740636e-06, 'epoch': 0.8082819615480357}
2024-12-24 20:55:39,457 - INFO - Training Logs at step 7000: {'loss': 22.0267, 'grad_norm': 15.460709571838379, 'learning_rate': 9.41797060218113e-06, 'epoch': 0.8141390772114272}
2024-12-24 20:56:45,524 - INFO - Training Logs at step 7050: {'loss': 22.4059, 'grad_norm': 11.42407512664795, 'learning_rate': 9.121621621621622e-06, 'epoch': 0.8199961928748188}
2024-12-24 20:57:51,905 - INFO - Training Logs at step 7100: {'loss': 21.5774, 'grad_norm': 12.541156768798828, 'learning_rate': 8.825272641062116e-06, 'epoch': 0.8258533085382104}
2024-12-24 20:58:57,769 - INFO - Training Logs at step 7150: {'loss': 22.0621, 'grad_norm': 12.663975715637207, 'learning_rate': 8.528923660502608e-06, 'epoch': 0.8317104242016019}
2024-12-24 21:00:03,896 - INFO - Training Logs at step 7200: {'loss': 22.0743, 'grad_norm': 12.275134086608887, 'learning_rate': 8.232574679943102e-06, 'epoch': 0.8375675398649934}
2024-12-24 21:01:10,029 - INFO - Training Logs at step 7250: {'loss': 22.1441, 'grad_norm': 11.863306999206543, 'learning_rate': 7.936225699383594e-06, 'epoch': 0.8434246555283851}
2024-12-24 21:02:16,446 - INFO - Training Logs at step 7300: {'loss': 22.2097, 'grad_norm': 21.26336669921875, 'learning_rate': 7.639876718824088e-06, 'epoch': 0.8492817711917766}
2024-12-24 21:03:22,622 - INFO - Training Logs at step 7350: {'loss': 21.8937, 'grad_norm': 13.499686241149902, 'learning_rate': 7.34352773826458e-06, 'epoch': 0.8551388868551681}
2024-12-24 21:04:28,730 - INFO - Training Logs at step 7400: {'loss': 21.8706, 'grad_norm': 11.382003784179688, 'learning_rate': 7.047178757705074e-06, 'epoch': 0.8609960025185598}
2024-12-24 21:05:35,692 - INFO - Training Logs at step 7450: {'loss': 21.8753, 'grad_norm': 13.389580726623535, 'learning_rate': 6.750829777145567e-06, 'epoch': 0.8668531181819513}
2024-12-24 21:06:42,040 - INFO - Training Logs at step 7500: {'loss': 22.0297, 'grad_norm': 13.717774391174316, 'learning_rate': 6.4544807965860596e-06, 'epoch': 0.8727102338453429}
2024-12-24 21:07:48,665 - INFO - Training Logs at step 7550: {'loss': 21.9114, 'grad_norm': 16.30647850036621, 'learning_rate': 6.1581318160265525e-06, 'epoch': 0.8785673495087344}
2024-12-24 21:08:55,217 - INFO - Training Logs at step 7600: {'loss': 21.9325, 'grad_norm': 14.273224830627441, 'learning_rate': 5.8617828354670455e-06, 'epoch': 0.884424465172126}
2024-12-24 21:10:01,466 - INFO - Training Logs at step 7650: {'loss': 21.6617, 'grad_norm': 12.530169486999512, 'learning_rate': 5.565433854907539e-06, 'epoch': 0.8902815808355176}
2024-12-24 21:11:07,707 - INFO - Training Logs at step 7700: {'loss': 22.0029, 'grad_norm': 12.260038375854492, 'learning_rate': 5.269084874348032e-06, 'epoch': 0.8961386964989091}
2024-12-24 21:12:13,938 - INFO - Training Logs at step 7750: {'loss': 22.1541, 'grad_norm': 13.448575019836426, 'learning_rate': 4.972735893788525e-06, 'epoch': 0.9019958121623006}
2024-12-24 21:13:20,218 - INFO - Training Logs at step 7800: {'loss': 21.961, 'grad_norm': 9.511909484863281, 'learning_rate': 4.676386913229019e-06, 'epoch': 0.9078529278256923}
2024-12-24 21:14:26,658 - INFO - Training Logs at step 7850: {'loss': 21.7699, 'grad_norm': 13.115096092224121, 'learning_rate': 4.380037932669512e-06, 'epoch': 0.9137100434890838}
2024-12-24 21:15:33,127 - INFO - Training Logs at step 7900: {'loss': 22.1015, 'grad_norm': 11.785858154296875, 'learning_rate': 4.083688952110005e-06, 'epoch': 0.9195671591524753}
2024-12-24 21:16:39,467 - INFO - Training Logs at step 7950: {'loss': 22.1932, 'grad_norm': 14.990983009338379, 'learning_rate': 3.7873399715504977e-06, 'epoch': 0.925424274815867}
2024-12-24 21:17:45,783 - INFO - Training Logs at step 8000: {'loss': 22.0042, 'grad_norm': 12.861942291259766, 'learning_rate': 3.4969179706021817e-06, 'epoch': 0.9312813904792585}
2024-12-24 21:18:52,009 - INFO - Training Logs at step 8050: {'loss': 21.5963, 'grad_norm': 12.699799537658691, 'learning_rate': 3.2005689900426746e-06, 'epoch': 0.93713850614265}
2024-12-24 21:19:58,378 - INFO - Training Logs at step 8100: {'loss': 22.0415, 'grad_norm': 11.874481201171875, 'learning_rate': 2.9042200094831676e-06, 'epoch': 0.9429956218060416}
2024-12-24 21:21:04,699 - INFO - Training Logs at step 8150: {'loss': 22.173, 'grad_norm': 11.696029663085938, 'learning_rate': 2.6078710289236606e-06, 'epoch': 0.9488527374694332}
2024-12-24 21:22:10,899 - INFO - Training Logs at step 8200: {'loss': 22.2255, 'grad_norm': 14.685493469238281, 'learning_rate': 2.3115220483641536e-06, 'epoch': 0.9547098531328247}
2024-12-24 21:23:16,981 - INFO - Training Logs at step 8250: {'loss': 22.0488, 'grad_norm': 13.45283031463623, 'learning_rate': 2.0151730678046466e-06, 'epoch': 0.9605669687962163}
2024-12-24 21:24:23,316 - INFO - Training Logs at step 8300: {'loss': 22.5996, 'grad_norm': 12.243948936462402, 'learning_rate': 1.71882408724514e-06, 'epoch': 0.9664240844596078}
2024-12-24 21:25:29,553 - INFO - Training Logs at step 8350: {'loss': 22.1654, 'grad_norm': 11.154451370239258, 'learning_rate': 1.4224751066856332e-06, 'epoch': 0.9722812001229995}
2024-12-24 21:26:35,626 - INFO - Training Logs at step 8400: {'loss': 22.4339, 'grad_norm': 9.965599060058594, 'learning_rate': 1.1261261261261262e-06, 'epoch': 0.978138315786391}
2024-12-24 21:27:41,972 - INFO - Training Logs at step 8450: {'loss': 22.0977, 'grad_norm': 12.292492866516113, 'learning_rate': 8.297771455666194e-07, 'epoch': 0.9839954314497825}
2024-12-24 21:28:48,543 - INFO - Training Logs at step 8500: {'loss': 21.6991, 'grad_norm': 9.393857955932617, 'learning_rate': 5.334281650071124e-07, 'epoch': 0.9898525471131742}
2024-12-24 21:29:37,718 - INFO - Model ytu-ce-cosmos/turkish-gpt2-large ince ayar işlemi başarıyla tamamlandı.
2024-12-24 21:29:37,718 - INFO - Model ve tokenizer kaydediliyor: ./models/turkish-gpt2-large_v3
2024-12-24 21:29:46,013 - INFO - Model ./models/turkish-gpt2-large_v3 dizinine başarıyla kaydedildi.
2024-12-24 21:29:46,013 - INFO - [SUCCESS] Eğitim tamamlandı: Model=ytu-ce-cosmos/turkish-gpt2-large, Dataset=v3
