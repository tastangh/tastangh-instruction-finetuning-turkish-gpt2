2024-12-24 14:44:10,502 - INFO - [INFO] Eğitim başlıyor: Model=ytu-ce-cosmos/turkish-gpt2-medium, Dataset=v3
2024-12-24 14:44:19,453 - INFO - Dataset başarıyla yüklendi: v3
2024-12-24 14:44:19,453 - INFO - Model ve tokenizer yükleniyor: ytu-ce-cosmos/turkish-gpt2-medium
2024-12-24 14:44:20,798 - INFO - Model ve tokenizer başarıyla yüklendi: ytu-ce-cosmos/turkish-gpt2-medium
2024-12-24 14:44:20,798 - INFO - Model ytu-ce-cosmos/turkish-gpt2-medium ince ayar işlemi başlatılıyor.
2024-12-24 14:48:01,604 - INFO - Training Logs at step 200: {'loss': 27.7284, 'grad_norm': 17.73516273498535, 'learning_rate': 0.0001, 'epoch': 0.011714231326783125}
2024-12-24 14:49:44,891 - INFO - Training Logs at step 300: {'loss': 25.4323, 'grad_norm': 11.081815719604492, 'learning_rate': 9.881460407776198e-05, 'epoch': 0.02342846265356625}
2024-12-24 14:51:27,603 - INFO - Training Logs at step 400: {'loss': 24.7875, 'grad_norm': 12.387796401977539, 'learning_rate': 9.762920815552396e-05, 'epoch': 0.035142693980349374}
2024-12-24 14:53:10,235 - INFO - Training Logs at step 500: {'loss': 24.402, 'grad_norm': 11.089061737060547, 'learning_rate': 9.644381223328592e-05, 'epoch': 0.0468569253071325}
2024-12-24 14:54:52,374 - INFO - Training Logs at step 600: {'loss': 24.4013, 'grad_norm': 10.453388214111328, 'learning_rate': 9.525841631104789e-05, 'epoch': 0.05857115663391563}
2024-12-24 14:56:33,592 - INFO - Training Logs at step 700: {'loss': 24.0532, 'grad_norm': 11.144664764404297, 'learning_rate': 9.407302038880987e-05, 'epoch': 0.07028538796069875}
2024-12-24 14:58:15,400 - INFO - Training Logs at step 800: {'loss': 24.2067, 'grad_norm': 9.954721450805664, 'learning_rate': 9.288762446657184e-05, 'epoch': 0.08199961928748188}
2024-12-24 14:59:57,165 - INFO - Training Logs at step 900: {'loss': 23.987, 'grad_norm': 10.113673210144043, 'learning_rate': 9.170222854433382e-05, 'epoch': 0.093713850614265}
2024-12-24 15:01:40,069 - INFO - Training Logs at step 1000: {'loss': 23.9849, 'grad_norm': 9.423467636108398, 'learning_rate': 9.051683262209578e-05, 'epoch': 0.10542808194104814}
2024-12-24 15:03:21,044 - INFO - Training Logs at step 1100: {'loss': 24.0042, 'grad_norm': 11.11050033569336, 'learning_rate': 8.933143669985776e-05, 'epoch': 0.11714231326783126}
2024-12-24 15:05:04,649 - INFO - Training Logs at step 1200: {'loss': 23.946, 'grad_norm': 10.546889305114746, 'learning_rate': 8.814604077761973e-05, 'epoch': 0.12885654459461438}
2024-12-24 15:06:46,870 - INFO - Training Logs at step 1300: {'loss': 23.7197, 'grad_norm': 19.545434951782227, 'learning_rate': 8.69606448553817e-05, 'epoch': 0.1405707759213975}
2024-12-24 15:08:30,169 - INFO - Training Logs at step 1400: {'loss': 24.0472, 'grad_norm': 12.731379508972168, 'learning_rate': 8.577524893314367e-05, 'epoch': 0.15228500724818064}
2024-12-24 15:10:12,345 - INFO - Training Logs at step 1500: {'loss': 23.6317, 'grad_norm': 12.276764869689941, 'learning_rate': 8.458985301090566e-05, 'epoch': 0.16399923857496376}
2024-12-24 15:11:55,564 - INFO - Training Logs at step 1600: {'loss': 24.033, 'grad_norm': 12.838677406311035, 'learning_rate': 8.340445708866762e-05, 'epoch': 0.17571346990174688}
2024-12-24 15:13:40,161 - INFO - Training Logs at step 1700: {'loss': 23.8119, 'grad_norm': 13.09886360168457, 'learning_rate': 8.22190611664296e-05, 'epoch': 0.18742770122853}
2024-12-24 15:15:22,001 - INFO - Training Logs at step 1800: {'loss': 23.5644, 'grad_norm': 9.747529983520508, 'learning_rate': 8.103366524419156e-05, 'epoch': 0.19914193255531312}
2024-12-24 15:17:05,668 - INFO - Training Logs at step 1900: {'loss': 24.0017, 'grad_norm': 15.1171236038208, 'learning_rate': 7.984826932195354e-05, 'epoch': 0.21085616388209627}
2024-12-24 15:18:50,363 - INFO - Training Logs at step 2000: {'loss': 23.7016, 'grad_norm': 11.289291381835938, 'learning_rate': 7.86628733997155e-05, 'epoch': 0.2225703952088794}
2024-12-24 15:20:33,907 - INFO - Training Logs at step 2100: {'loss': 23.7672, 'grad_norm': 11.979965209960938, 'learning_rate': 7.747747747747748e-05, 'epoch': 0.2342846265356625}
2024-12-24 15:22:17,148 - INFO - Training Logs at step 2200: {'loss': 23.6418, 'grad_norm': 13.635129928588867, 'learning_rate': 7.629208155523946e-05, 'epoch': 0.24599885786244563}
2024-12-24 15:23:59,630 - INFO - Training Logs at step 2300: {'loss': 23.7786, 'grad_norm': 9.340861320495605, 'learning_rate': 7.510668563300143e-05, 'epoch': 0.25771308918922875}
2024-12-24 15:25:43,520 - INFO - Training Logs at step 2400: {'loss': 23.5954, 'grad_norm': 13.241347312927246, 'learning_rate': 7.39212897107634e-05, 'epoch': 0.26942732051601187}
2024-12-24 15:27:29,403 - INFO - Training Logs at step 2500: {'loss': 23.2145, 'grad_norm': 11.414851188659668, 'learning_rate': 7.273589378852537e-05, 'epoch': 0.281141551842795}
2024-12-24 15:29:12,596 - INFO - Training Logs at step 2600: {'loss': 23.5654, 'grad_norm': 11.438433647155762, 'learning_rate': 7.155049786628735e-05, 'epoch': 0.29285578316957817}
2024-12-24 15:30:55,546 - INFO - Training Logs at step 2700: {'loss': 23.6744, 'grad_norm': 13.26671314239502, 'learning_rate': 7.036510194404932e-05, 'epoch': 0.3045700144963613}
2024-12-24 15:32:37,275 - INFO - Training Logs at step 2800: {'loss': 23.9081, 'grad_norm': 12.660877227783203, 'learning_rate': 6.917970602181128e-05, 'epoch': 0.3162842458231444}
2024-12-24 15:34:19,159 - INFO - Training Logs at step 2900: {'loss': 23.3523, 'grad_norm': 9.0162935256958, 'learning_rate': 6.799431009957327e-05, 'epoch': 0.3279984771499275}
2024-12-24 15:36:01,139 - INFO - Training Logs at step 3000: {'loss': 23.2364, 'grad_norm': 14.064690589904785, 'learning_rate': 6.680891417733523e-05, 'epoch': 0.33971270847671065}
2024-12-24 15:37:43,570 - INFO - Training Logs at step 3100: {'loss': 23.1709, 'grad_norm': 9.913713455200195, 'learning_rate': 6.562351825509721e-05, 'epoch': 0.35142693980349377}
2024-12-24 15:39:26,113 - INFO - Training Logs at step 3200: {'loss': 23.7309, 'grad_norm': 14.030929565429688, 'learning_rate': 6.443812233285917e-05, 'epoch': 0.3631411711302769}
2024-12-24 15:41:09,253 - INFO - Training Logs at step 3300: {'loss': 23.2912, 'grad_norm': 14.467824935913086, 'learning_rate': 6.325272641062116e-05, 'epoch': 0.37485540245706}
2024-12-24 15:42:51,181 - INFO - Training Logs at step 3400: {'loss': 23.2908, 'grad_norm': 13.269493103027344, 'learning_rate': 6.206733048838312e-05, 'epoch': 0.3865696337838431}
2024-12-24 15:44:33,381 - INFO - Training Logs at step 3500: {'loss': 23.4195, 'grad_norm': 12.357903480529785, 'learning_rate': 6.0881934566145096e-05, 'epoch': 0.39828386511062625}
2024-12-24 15:46:14,709 - INFO - Training Logs at step 3600: {'loss': 23.2739, 'grad_norm': 14.094840049743652, 'learning_rate': 5.9696538643907064e-05, 'epoch': 0.4099980964374094}
2024-12-24 15:47:55,460 - INFO - Training Logs at step 3700: {'loss': 23.1612, 'grad_norm': 13.19537353515625, 'learning_rate': 5.8511142721669047e-05, 'epoch': 0.42171232776419254}
2024-12-24 15:49:38,031 - INFO - Training Logs at step 3800: {'loss': 23.2438, 'grad_norm': 10.662626266479492, 'learning_rate': 5.7325746799431015e-05, 'epoch': 0.43342655909097566}
2024-12-24 15:51:18,714 - INFO - Training Logs at step 3900: {'loss': 23.1281, 'grad_norm': 13.235940933227539, 'learning_rate': 5.6140350877192984e-05, 'epoch': 0.4451407904177588}
2024-12-24 15:53:00,749 - INFO - Training Logs at step 4000: {'loss': 23.4527, 'grad_norm': 13.453302383422852, 'learning_rate': 5.4954954954954966e-05, 'epoch': 0.4568550217445419}
2024-12-24 15:54:43,286 - INFO - Training Logs at step 4100: {'loss': 23.5973, 'grad_norm': 13.083133697509766, 'learning_rate': 5.3769559032716934e-05, 'epoch': 0.468569253071325}
2024-12-24 15:56:25,667 - INFO - Training Logs at step 4200: {'loss': 23.0941, 'grad_norm': 11.137446403503418, 'learning_rate': 5.25841631104789e-05, 'epoch': 0.48028348439810814}
2024-12-24 15:58:07,071 - INFO - Training Logs at step 4300: {'loss': 23.1666, 'grad_norm': 9.003256797790527, 'learning_rate': 5.139876718824087e-05, 'epoch': 0.49199771572489126}
2024-12-24 15:59:48,612 - INFO - Training Logs at step 4400: {'loss': 22.7086, 'grad_norm': 12.650212287902832, 'learning_rate': 5.0213371266002854e-05, 'epoch': 0.5037119470516744}
2024-12-24 16:01:32,510 - INFO - Training Logs at step 4500: {'loss': 23.359, 'grad_norm': 12.257572174072266, 'learning_rate': 4.902797534376482e-05, 'epoch': 0.5154261783784575}
2024-12-24 16:03:16,314 - INFO - Training Logs at step 4600: {'loss': 22.9698, 'grad_norm': 10.146281242370605, 'learning_rate': 4.784257942152679e-05, 'epoch': 0.5271404097052407}
2024-12-24 16:04:58,602 - INFO - Training Logs at step 4700: {'loss': 23.1021, 'grad_norm': 15.196788787841797, 'learning_rate': 4.6657183499288766e-05, 'epoch': 0.5388546410320237}
2024-12-24 16:06:41,446 - INFO - Training Logs at step 4800: {'loss': 23.1022, 'grad_norm': 8.934985160827637, 'learning_rate': 4.547178757705074e-05, 'epoch': 0.5505688723588069}
2024-12-24 16:08:33,006 - INFO - Training Logs at step 4900: {'loss': 23.4214, 'grad_norm': 11.024235725402832, 'learning_rate': 4.428639165481271e-05, 'epoch': 0.56228310368559}
2024-12-24 16:10:15,000 - INFO - Training Logs at step 5000: {'loss': 23.1009, 'grad_norm': 13.148449897766113, 'learning_rate': 4.3100995732574685e-05, 'epoch': 0.5739973350123732}
2024-12-24 16:11:57,875 - INFO - Training Logs at step 5100: {'loss': 22.8554, 'grad_norm': 12.296567916870117, 'learning_rate': 4.1915599810336654e-05, 'epoch': 0.5857115663391563}
2024-12-24 16:13:40,683 - INFO - Training Logs at step 5200: {'loss': 22.8765, 'grad_norm': 11.053175926208496, 'learning_rate': 4.073020388809863e-05, 'epoch': 0.5974257976659394}
2024-12-24 16:15:23,103 - INFO - Training Logs at step 5300: {'loss': 22.8276, 'grad_norm': 11.133230209350586, 'learning_rate': 3.95448079658606e-05, 'epoch': 0.6091400289927226}
2024-12-24 16:17:05,541 - INFO - Training Logs at step 5400: {'loss': 23.1897, 'grad_norm': 12.892312049865723, 'learning_rate': 3.835941204362257e-05, 'epoch': 0.6208542603195056}
2024-12-24 16:18:49,645 - INFO - Training Logs at step 5500: {'loss': 22.9148, 'grad_norm': 12.022116661071777, 'learning_rate': 3.717401612138454e-05, 'epoch': 0.6325684916462888}
2024-12-24 16:20:32,012 - INFO - Training Logs at step 5600: {'loss': 23.0817, 'grad_norm': 17.510236740112305, 'learning_rate': 3.598862019914652e-05, 'epoch': 0.6442827229730719}
2024-12-24 16:22:13,521 - INFO - Training Logs at step 5700: {'loss': 23.1834, 'grad_norm': 15.98391342163086, 'learning_rate': 3.480322427690849e-05, 'epoch': 0.655996954299855}
2024-12-24 16:23:55,538 - INFO - Training Logs at step 5800: {'loss': 23.2045, 'grad_norm': 13.203950881958008, 'learning_rate': 3.361782835467046e-05, 'epoch': 0.6677111856266381}
2024-12-24 16:25:37,685 - INFO - Training Logs at step 5900: {'loss': 22.9752, 'grad_norm': 11.0571928024292, 'learning_rate': 3.2432432432432436e-05, 'epoch': 0.6794254169534213}
2024-12-24 16:27:19,268 - INFO - Training Logs at step 6000: {'loss': 23.0328, 'grad_norm': 15.677666664123535, 'learning_rate': 3.1247036510194405e-05, 'epoch': 0.6911396482802045}
2024-12-24 16:29:02,008 - INFO - Training Logs at step 6100: {'loss': 23.2201, 'grad_norm': 12.732053756713867, 'learning_rate': 3.006164058795638e-05, 'epoch': 0.7028538796069875}
2024-12-24 16:30:43,968 - INFO - Training Logs at step 6200: {'loss': 23.0595, 'grad_norm': 11.959198951721191, 'learning_rate': 2.887624466571835e-05, 'epoch': 0.7145681109337707}
2024-12-24 16:32:27,560 - INFO - Training Logs at step 6300: {'loss': 23.14, 'grad_norm': 14.031566619873047, 'learning_rate': 2.7690848743480324e-05, 'epoch': 0.7262823422605538}
2024-12-24 16:34:10,282 - INFO - Training Logs at step 6400: {'loss': 23.2594, 'grad_norm': 12.472769737243652, 'learning_rate': 2.6505452821242293e-05, 'epoch': 0.737996573587337}
2024-12-24 16:35:51,105 - INFO - Training Logs at step 6500: {'loss': 22.9348, 'grad_norm': 11.274284362792969, 'learning_rate': 2.5320056899004268e-05, 'epoch': 0.74971080491412}
2024-12-24 16:37:32,445 - INFO - Training Logs at step 6600: {'loss': 23.1118, 'grad_norm': 14.831293106079102, 'learning_rate': 2.413466097676624e-05, 'epoch': 0.7614250362409032}
2024-12-24 16:39:15,062 - INFO - Training Logs at step 6700: {'loss': 23.1812, 'grad_norm': 9.40302848815918, 'learning_rate': 2.2949265054528212e-05, 'epoch': 0.7731392675676863}
2024-12-24 16:40:58,386 - INFO - Training Logs at step 6800: {'loss': 23.0379, 'grad_norm': 8.92690372467041, 'learning_rate': 2.1763869132290184e-05, 'epoch': 0.7848534988944694}
2024-12-24 16:42:39,531 - INFO - Training Logs at step 6900: {'loss': 23.2922, 'grad_norm': 12.413092613220215, 'learning_rate': 2.0578473210052156e-05, 'epoch': 0.7965677302212525}
2024-12-24 16:44:20,605 - INFO - Training Logs at step 7000: {'loss': 23.318, 'grad_norm': 10.211263656616211, 'learning_rate': 1.939307728781413e-05, 'epoch': 0.8082819615480357}
2024-12-24 16:46:02,067 - INFO - Training Logs at step 7100: {'loss': 23.0904, 'grad_norm': 10.947723388671875, 'learning_rate': 1.8207681365576103e-05, 'epoch': 0.8199961928748188}
2024-12-24 16:47:43,382 - INFO - Training Logs at step 7200: {'loss': 22.8284, 'grad_norm': 13.294501304626465, 'learning_rate': 1.7022285443338075e-05, 'epoch': 0.8317104242016019}
2024-12-24 16:49:24,704 - INFO - Training Logs at step 7300: {'loss': 23.0915, 'grad_norm': 11.367230415344238, 'learning_rate': 1.5836889521100047e-05, 'epoch': 0.8434246555283851}
2024-12-24 16:51:05,812 - INFO - Training Logs at step 7400: {'loss': 23.0552, 'grad_norm': 13.554712295532227, 'learning_rate': 1.465149359886202e-05, 'epoch': 0.8551388868551681}
2024-12-24 16:52:49,636 - INFO - Training Logs at step 7500: {'loss': 22.8389, 'grad_norm': 13.490187644958496, 'learning_rate': 1.3466097676623992e-05, 'epoch': 0.8668531181819513}
2024-12-24 16:54:31,360 - INFO - Training Logs at step 7600: {'loss': 22.8751, 'grad_norm': 14.339116096496582, 'learning_rate': 1.2280701754385964e-05, 'epoch': 0.8785673495087344}
2024-12-24 16:56:15,550 - INFO - Training Logs at step 7700: {'loss': 22.7149, 'grad_norm': 13.365952491760254, 'learning_rate': 1.1095305832147938e-05, 'epoch': 0.8902815808355176}
2024-12-24 16:57:59,542 - INFO - Training Logs at step 7800: {'loss': 23.0274, 'grad_norm': 13.38515567779541, 'learning_rate': 9.90990990990991e-06, 'epoch': 0.9019958121623006}
2024-12-24 16:59:42,909 - INFO - Training Logs at step 7900: {'loss': 22.8171, 'grad_norm': 13.053733825683594, 'learning_rate': 8.724513987671882e-06, 'epoch': 0.9137100434890838}
2024-12-24 17:01:24,829 - INFO - Training Logs at step 8000: {'loss': 23.1418, 'grad_norm': 15.26147747039795, 'learning_rate': 7.539118065433855e-06, 'epoch': 0.925424274815867}
2024-12-24 17:03:06,280 - INFO - Training Logs at step 8100: {'loss': 22.7318, 'grad_norm': 12.439624786376953, 'learning_rate': 6.353722143195828e-06, 'epoch': 0.93713850614265}
2024-12-24 17:04:58,088 - INFO - Training Logs at step 8200: {'loss': 23.0986, 'grad_norm': 11.925247192382812, 'learning_rate': 5.1683262209578e-06, 'epoch': 0.9488527374694332}
2024-12-24 17:06:42,759 - INFO - Training Logs at step 8300: {'loss': 23.0822, 'grad_norm': 14.115823745727539, 'learning_rate': 3.982930298719772e-06, 'epoch': 0.9605669687962163}
2024-12-24 17:08:23,990 - INFO - Training Logs at step 8400: {'loss': 23.3383, 'grad_norm': 11.733534812927246, 'learning_rate': 2.797534376481745e-06, 'epoch': 0.9722812001229995}
2024-12-24 17:10:06,057 - INFO - Training Logs at step 8500: {'loss': 23.1602, 'grad_norm': 12.119162559509277, 'learning_rate': 1.6121384542437176e-06, 'epoch': 0.9839954314497825}
2024-12-24 17:10:43,716 - INFO - Model ytu-ce-cosmos/turkish-gpt2-medium ince ayar işlemi başarıyla tamamlandı.
2024-12-24 17:10:43,716 - INFO - Model ve tokenizer kaydediliyor: ./models/turkish-gpt2-medium_v3
2024-12-24 17:10:44,361 - INFO - Model ./models/turkish-gpt2-medium_v3 dizinine başarıyla kaydedildi.
2024-12-24 17:10:44,362 - INFO - [SUCCESS] Eğitim tamamlandı: Model=ytu-ce-cosmos/turkish-gpt2-medium, Dataset=v3
