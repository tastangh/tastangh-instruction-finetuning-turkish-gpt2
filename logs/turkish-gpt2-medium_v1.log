2024-12-24 22:34:40,917 - INFO - [INFO] Eğitim başlıyor: Model=ytu-ce-cosmos/turkish-gpt2-medium, Dataset=v1
2024-12-24 22:34:42,518 - INFO - Dataset başarıyla yüklendi: v1
2024-12-24 22:34:42,519 - INFO - Model ve tokenizer yükleniyor: ytu-ce-cosmos/turkish-gpt2-medium
2024-12-24 22:34:44,410 - INFO - Model ve tokenizer başarıyla yüklendi: ytu-ce-cosmos/turkish-gpt2-medium
2024-12-24 22:34:44,410 - INFO - Model ytu-ce-cosmos/turkish-gpt2-medium ince ayar işlemi başlatılıyor.
2024-12-24 22:34:49,216 - INFO - Dataset başarıyla işlendi: max_seq_length=256
2024-12-24 22:36:17,221 - INFO - Training Logs at step 100: {'loss': 28.2684, 'grad_norm': 8.87447452545166, 'learning_rate': 2.4e-05, 'epoch': 0.023909145248057383}
2024-12-24 22:37:00,294 - INFO - Training Logs at step 150: {'loss': 26.6212, 'grad_norm': 15.963528633117676, 'learning_rate': 4.9e-05, 'epoch': 0.04781829049611477}
2024-12-24 22:37:43,902 - INFO - Training Logs at step 200: {'loss': 25.226, 'grad_norm': 13.05618667602539, 'learning_rate': 4.8794575590155705e-05, 'epoch': 0.07172743574417215}
2024-12-24 22:38:26,755 - INFO - Training Logs at step 250: {'loss': 25.2876, 'grad_norm': 12.74654483795166, 'learning_rate': 4.753892516323456e-05, 'epoch': 0.09563658099222953}
2024-12-24 22:39:10,071 - INFO - Training Logs at step 300: {'loss': 26.0121, 'grad_norm': 18.12967300415039, 'learning_rate': 4.6283274736313415e-05, 'epoch': 0.1195457262402869}
2024-12-24 22:39:53,845 - INFO - Training Logs at step 350: {'loss': 25.1948, 'grad_norm': 17.851802825927734, 'learning_rate': 4.502762430939227e-05, 'epoch': 0.1434548714883443}
2024-12-24 22:40:37,389 - INFO - Training Logs at step 400: {'loss': 25.14, 'grad_norm': 20.85698890686035, 'learning_rate': 4.3771973882471125e-05, 'epoch': 0.16736401673640167}
2024-12-24 22:41:20,349 - INFO - Training Logs at step 450: {'loss': 24.6951, 'grad_norm': 20.117359161376953, 'learning_rate': 4.251632345554998e-05, 'epoch': 0.19127316198445907}
2024-12-24 22:42:02,741 - INFO - Training Logs at step 500: {'loss': 24.8989, 'grad_norm': 17.479528427124023, 'learning_rate': 4.1285786037167256e-05, 'epoch': 0.21518230723251644}
2024-12-24 22:42:45,582 - INFO - Training Logs at step 550: {'loss': 25.0507, 'grad_norm': 22.02590560913086, 'learning_rate': 4.003013561024611e-05, 'epoch': 0.2390914524805738}
2024-12-24 22:43:28,799 - INFO - Training Logs at step 600: {'loss': 24.5857, 'grad_norm': 17.006093978881836, 'learning_rate': 3.8774485183324966e-05, 'epoch': 0.2630005977286312}
2024-12-24 22:44:11,976 - INFO - Training Logs at step 650: {'loss': 24.2489, 'grad_norm': 23.81254005432129, 'learning_rate': 3.751883475640382e-05, 'epoch': 0.2869097429766886}
2024-12-24 22:44:54,559 - INFO - Training Logs at step 700: {'loss': 24.6719, 'grad_norm': 13.858941078186035, 'learning_rate': 3.6263184329482676e-05, 'epoch': 0.31081888822474596}
2024-12-24 22:45:36,311 - INFO - Training Logs at step 750: {'loss': 24.4635, 'grad_norm': 23.767271041870117, 'learning_rate': 3.500753390256153e-05, 'epoch': 0.33472803347280333}
2024-12-24 22:46:17,993 - INFO - Training Logs at step 800: {'loss': 24.1717, 'grad_norm': 15.613504409790039, 'learning_rate': 3.3751883475640386e-05, 'epoch': 0.3586371787208607}
2024-12-24 22:46:59,988 - INFO - Training Logs at step 850: {'loss': 24.861, 'grad_norm': 18.48759651184082, 'learning_rate': 3.249623304871924e-05, 'epoch': 0.38254632396891813}
2024-12-24 22:47:41,618 - INFO - Training Logs at step 900: {'loss': 24.6586, 'grad_norm': 17.92099380493164, 'learning_rate': 3.1240582621798096e-05, 'epoch': 0.4064554692169755}
2024-12-24 22:48:23,172 - INFO - Training Logs at step 950: {'loss': 23.8862, 'grad_norm': 18.043704986572266, 'learning_rate': 2.9984932194876947e-05, 'epoch': 0.4303646144650329}
2024-12-24 22:49:04,365 - INFO - Training Logs at step 1000: {'loss': 23.8133, 'grad_norm': 19.42032241821289, 'learning_rate': 2.8729281767955802e-05, 'epoch': 0.45427375971309025}
2024-12-24 22:49:46,167 - INFO - Training Logs at step 1050: {'loss': 24.1091, 'grad_norm': 14.982366561889648, 'learning_rate': 2.7473631341034657e-05, 'epoch': 0.4781829049611476}
2024-12-24 22:50:30,557 - INFO - Training Logs at step 1100: {'loss': 24.0069, 'grad_norm': 11.679011344909668, 'learning_rate': 2.621798091411351e-05, 'epoch': 0.502092050209205}
2024-12-24 22:51:14,655 - INFO - Training Logs at step 1150: {'loss': 24.3512, 'grad_norm': 16.556241989135742, 'learning_rate': 2.4962330487192367e-05, 'epoch': 0.5260011954572624}
2024-12-24 22:51:58,630 - INFO - Training Logs at step 1200: {'loss': 24.2434, 'grad_norm': 15.252291679382324, 'learning_rate': 2.3706680060271222e-05, 'epoch': 0.5499103407053197}
2024-12-24 22:52:43,349 - INFO - Training Logs at step 1250: {'loss': 24.3682, 'grad_norm': 16.097280502319336, 'learning_rate': 2.2451029633350077e-05, 'epoch': 0.5738194859533772}
2024-12-24 22:53:27,670 - INFO - Training Logs at step 1300: {'loss': 24.5541, 'grad_norm': 20.579587936401367, 'learning_rate': 2.1195379206428932e-05, 'epoch': 0.5977286312014346}
2024-12-24 22:54:11,832 - INFO - Training Logs at step 1350: {'loss': 23.6192, 'grad_norm': 14.757991790771484, 'learning_rate': 1.996484178804621e-05, 'epoch': 0.6216377764494919}
2024-12-24 22:54:56,502 - INFO - Training Logs at step 1400: {'loss': 23.8567, 'grad_norm': 18.385465621948242, 'learning_rate': 1.8709191361125063e-05, 'epoch': 0.6455469216975493}
2024-12-24 22:55:40,788 - INFO - Training Logs at step 1450: {'loss': 24.2059, 'grad_norm': 17.123563766479492, 'learning_rate': 1.7453540934203918e-05, 'epoch': 0.6694560669456067}
2024-12-24 22:56:24,669 - INFO - Training Logs at step 1500: {'loss': 24.5187, 'grad_norm': 16.659183502197266, 'learning_rate': 1.6197890507282773e-05, 'epoch': 0.6933652121936641}
2024-12-24 22:57:08,886 - INFO - Training Logs at step 1550: {'loss': 24.5323, 'grad_norm': 18.025575637817383, 'learning_rate': 1.4942240080361628e-05, 'epoch': 0.7172743574417214}
2024-12-24 22:57:53,684 - INFO - Training Logs at step 1600: {'loss': 23.9084, 'grad_norm': 16.676725387573242, 'learning_rate': 1.3686589653440483e-05, 'epoch': 0.7411835026897788}
2024-12-24 22:58:37,368 - INFO - Training Logs at step 1650: {'loss': 23.7452, 'grad_norm': 15.23565673828125, 'learning_rate': 1.2430939226519338e-05, 'epoch': 0.7650926479378363}
2024-12-24 22:59:21,958 - INFO - Training Logs at step 1700: {'loss': 24.2362, 'grad_norm': 18.47001838684082, 'learning_rate': 1.1175288799598193e-05, 'epoch': 0.7890017931858936}
2024-12-24 23:00:06,511 - INFO - Training Logs at step 1750: {'loss': 24.3803, 'grad_norm': 15.134865760803223, 'learning_rate': 9.919638372677048e-06, 'epoch': 0.812910938433951}
2024-12-24 23:00:50,467 - INFO - Training Logs at step 1800: {'loss': 24.3578, 'grad_norm': 12.57273006439209, 'learning_rate': 8.663987945755903e-06, 'epoch': 0.8368200836820083}
2024-12-24 23:01:34,769 - INFO - Training Logs at step 1850: {'loss': 23.7263, 'grad_norm': 14.344367980957031, 'learning_rate': 7.408337518834757e-06, 'epoch': 0.8607292289300658}
2024-12-24 23:02:19,191 - INFO - Training Logs at step 1900: {'loss': 24.437, 'grad_norm': 21.00242805480957, 'learning_rate': 6.152687091913612e-06, 'epoch': 0.8846383741781231}
2024-12-24 23:03:03,245 - INFO - Training Logs at step 1950: {'loss': 23.8993, 'grad_norm': 14.930611610412598, 'learning_rate': 4.897036664992467e-06, 'epoch': 0.9085475194261805}
2024-12-24 23:03:47,344 - INFO - Training Logs at step 2000: {'loss': 24.431, 'grad_norm': 15.215531349182129, 'learning_rate': 3.6413862380713213e-06, 'epoch': 0.9324566646742379}
2024-12-24 23:04:32,112 - INFO - Training Logs at step 2050: {'loss': 23.9444, 'grad_norm': 23.57234764099121, 'learning_rate': 2.385735811150176e-06, 'epoch': 0.9563658099222953}
2024-12-24 23:05:09,443 - INFO - Model ytu-ce-cosmos/turkish-gpt2-medium ince ayar işlemi başarıyla tamamlandı.
2024-12-24 23:05:09,444 - INFO - Model ve tokenizer kaydediliyor: ./models/turkish-gpt2-medium_v1
2024-12-24 23:05:14,041 - INFO - Model ./models/turkish-gpt2-medium_v1 dizinine başarıyla kaydedildi.
2024-12-24 23:05:14,041 - INFO - [SUCCESS] Eğitim tamamlandı: Model=ytu-ce-cosmos/turkish-gpt2-medium, Dataset=v1
